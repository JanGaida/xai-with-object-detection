{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2_StA.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYanvulZPcFu"
      },
      "source": [
        "# Preparations\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrzrcM3DDG0W"
      },
      "source": [
        "## *Requirements*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S09DtqmbEeP6"
      },
      "source": [
        "*In order to run this notebook we rely on specifc package-versions; here we will downgrade these nessecarry packages.*\n",
        "\n",
        "*After it's completion it is **required to restart** current running runtime-enviroment, this can be done by clicking 'Runtime' > 'Reset runtime' in the menubar.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apcyw5HE1UpI"
      },
      "source": [
        "#!pip2 uninstall -y numpy\n",
        "#!pip3 uninstall -y numpy\n",
        "#!pip2 install numpy==1.13.0\n",
        "#!pip3 install numpy==1.13.0\n",
        "#!pip uninstall -y torchtext fastai\n",
        "#!pip install --upgrade numpy==1.13.0 \n",
        "#!pip install torch==0.4.1 torchvision==0.1.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK2UMyEqGaT-"
      },
      "source": [
        "## *Versioning*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KC2dB9rOFTII"
      },
      "source": [
        "import torch\n",
        "import PIL\n",
        "import numpy as np\n",
        "\n",
        "print('Installed Packegesversions:\\n - PyTroch: {}\\n - Pillow:  {}\\n - Numpy:   {}'.format(torch.__version__, PIL.__version__, np.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inwG1d3aP7R_"
      },
      "source": [
        "## *Imports*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhzzfR5n5VxX"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython.display import HTML, display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-0els8DQFm1"
      },
      "source": [
        "\n",
        "## *CNN-Visualization-Framework*\n",
        "\n",
        "* *Author: Utku Ozbulak*\n",
        "\n",
        "* *Year: 2019*\n",
        "\n",
        "* *Github: [utkuozbulak/pytorch-cnn-visualizations](https://github.com/utkuozbulak/pytorch-cnn-visualizations)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cy6Ef_3vRilq"
      },
      "source": [
        "We start by cloning this repository and checkout at a specifc commit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM26SQ4L6ZA-"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/utkuozbulak/pytorch-cnn-visualizations.git\n",
        "%cd /content/pytorch-cnn-visualizations\n",
        "!git checkout 66af4935d76cb0b597c33068026ca2a8e1c562dc\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8avycvDRsw5"
      },
      "source": [
        "Now will make the delcared classes, variables and functions importable:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-OEzfPk1oya"
      },
      "source": [
        "%%capture\n",
        "%cd /content/pytorch-cnn-visualizations\n",
        "with open('__init__.py', 'w') as f:\n",
        "  f.write('')\n",
        "%cd /content\n",
        "sys.path.append('/content/pytorch-cnn-visualizations/src')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5uO4qv5SFOV"
      },
      "source": [
        "And will finally import used classes, variables and functions into this python-enviorment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIHXM2SR_ZXI"
      },
      "source": [
        "from gradcam import GradCam, CamExtractor\n",
        "from misc_functions import preprocess_image, save_image, apply_colormap_on_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37w2AKgh4CuP"
      },
      "source": [
        "## *Utilities*\n",
        "\n",
        "Here we declare some usefull functions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pkbJNjm7o8R"
      },
      "source": [
        "To show a HTML-progress bar when doing some intesive tasks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtMIBa2q4C-X"
      },
      "source": [
        "PROGRESS_BAR = None\n",
        "PROGRESS_BAR_VALUE = 0\n",
        "PROGRESS_BAR_MAX_VALUE = 100\n",
        "\n",
        "def progressbar(value, max_value):\n",
        "  \"\"\"\n",
        "  Creates a HTML-Progressbar\n",
        "\n",
        "  @param value: the value to set the prograssbar to\n",
        "  @param max_value: the max-value to set the prograssbar to\n",
        "  \"\"\"\n",
        "  return HTML(f'<progress value=\\'{value/max_value}\\' max=\\'{max}\\' style=\\'width: 100%\\'>\\'{value}%\\'</progress><label>Finished {value} / {max_value}</label>')   \n",
        "\n",
        "def display_progress_bar(init_value, max_value):\n",
        "  \"\"\"\n",
        "  Initializes and displays a HTML-Progressbar\n",
        "\n",
        "  @param init_value: the initial value to set the prograssbar to\n",
        "  @param max_value: the max-value to set the prograssbar to\n",
        "  \"\"\"\n",
        "  global PROGRESS_BAR\n",
        "  global PROGRESS_BAR_VALUE\n",
        "  global PROGRESS_BAR_MAX_VALUE\n",
        "  PROGRESS_BAR_VALUE = init_value\n",
        "  PROGRESS_BAR_MAX_VALUE = max_value\n",
        "  PROGRESS_BAR = display(progressbar(PROGRESS_BAR_VALUE, PROGRESS_BAR_MAX_VALUE), display_id=True)\n",
        "\n",
        "def update_progress_bar():\n",
        "  \"\"\"\n",
        "  Will incrementaly update the progress-value and update the displayed HTML-Progressbar\n",
        "  \"\"\"\n",
        "  global PROGRESS_BAR\n",
        "  global PROGRESS_BAR_VALUE\n",
        "  global PROGRESS_BAR_MAX_VALUE\n",
        "  PROGRESS_BAR_VALUE = PROGRESS_BAR_VALUE + 1\n",
        "  PROGRESS_BAR.update(progressbar(PROGRESS_BAR_VALUE, PROGRESS_BAR_MAX_VALUE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oea1HGrRhOP"
      },
      "source": [
        "Some functionality to display multiple images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsNL2mktPBkd"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def extract_first_numbers(txt: str) -> str:\n",
        "  \"\"\"\n",
        "  Will extract all numbers out of given string\n",
        "\n",
        "  @param txt: the text to extract from\n",
        "\n",
        "  @return: the extracted numbers \n",
        "  \"\"\"\n",
        "  return ''.join([s for s in txt if s.isdigit()])\n",
        "\n",
        "def plot_images(image_paths: [str], columns: int, title: str, figsize: (int, int), tfunc):\n",
        "  \"\"\"\n",
        "  Will plot given images\n",
        "\n",
        "  @param image_paths: the paths of the images to display\n",
        "  @param columns: number of colums to use\n",
        "  @param title: the title of the figure\n",
        "  @param figsize: the sizes used for the figure\n",
        "  @param tfunc: function called to transform a filename into a more meaningfull str\n",
        "  \"\"\"\n",
        "  rows = math.ceil(len(image_paths)/columns)\n",
        "  fig, axes = plt.subplots(nrows=rows, ncols=columns, figsize=figsize)\n",
        "\n",
        "  # column titles\n",
        "  column_titles = []\n",
        "  for path in image_paths[0:3]:\n",
        "    column_titles.append(tfunc(path))\n",
        "  for ax, ct in zip(axes[0], column_titles):\n",
        "    ax.set_title(ct, fontsize='16')\n",
        "\n",
        "  # row titles\n",
        "  row_titles = []\n",
        "  for image_path in image_paths[::columns]:\n",
        "    row_titles.append('Layer ' + extract_first_numbers(image_path.split('/')[-1]))\n",
        "  for ax, rt in zip(axes[:,0], row_titles):\n",
        "    ax.set_ylabel(rt, rotation=90, fontsize='16')\n",
        "\n",
        "  # image\n",
        "  for i, cell in enumerate(axes.flat):\n",
        "    cell.imshow(mpimg.imread(image_paths[i]))\n",
        "\n",
        "  # styling\n",
        "  fig.text(0.5, 1.003, title, fontsize='20', horizontalalignment='center', verticalalignment='top')\n",
        "  fig.tight_layout()\n",
        "  fig.patch.set_facecolor('xkcd:white')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDApCGjhRhf2"
      },
      "source": [
        "Other utility-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUDXVgTBRlKA"
      },
      "source": [
        "def chunks(lst, n):\n",
        "    \"\"\" \n",
        "    Yield successive n-sized chunks from lst.\n",
        "\n",
        "    @param lst: the list to split\n",
        "    @param n: the chunks to split the given list into\n",
        "    \"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eWRJXF_SiRX"
      },
      "source": [
        "# Image-Samples\n",
        "\n",
        "---\n",
        "\n",
        "Here we declare a helper-class for our sample-images, which manages indices and offered some useful access methods to oure sample data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx8sMPnwT80q"
      },
      "source": [
        "class ImageSamples:\n",
        "  \"\"\"\n",
        "  A helper-class for Image-Sampls\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, image_paths: [], targeted_class: [] = None, start_index: int = -1):\n",
        "    \"\"\"\n",
        "    Init\n",
        "\n",
        "    @param image_paths: list of paths to images\n",
        "    @param targeted_class: list of targeted classes, if None the most likely detected class will be targeted\n",
        "    @param start_index: internal inital index\n",
        "    \"\"\"\n",
        "    self.__samples = image_paths\n",
        "    assert len(self.__samples) >= 1, 'There must be at least one given sample'\n",
        "    if targeted_class is None:\n",
        "      self.__classes = [None] * len(self.__samples)\n",
        "    else:\n",
        "      self.__classes = targeted_class\n",
        "      assert len(self.__samples) == len(self.__classes)  , 'Targeted classes must be of same length as given samples'\n",
        "    self.__i = start_index\n",
        "  \n",
        "  def next(self) -> bool:\n",
        "    \"\"\"\n",
        "    Will incrementality increase the index internaly used.\n",
        "\n",
        "    @return: whether there is a element left\n",
        "    \"\"\"\n",
        "    i = 1 + self.__i\n",
        "    if i >= len(self.__samples) or i < 0:\n",
        "      return False\n",
        "    else:\n",
        "      self.__i = i\n",
        "      return True\n",
        "\n",
        "  def reset_index(self):\n",
        "    \"\"\"\n",
        "    Will reset the index, tho the next-function can be called again\n",
        "    \"\"\"\n",
        "    self.__i = -1\n",
        "  \n",
        "  def get_preprocessed_image(self, colorcodec: str = 'RGB') -> Image:\n",
        "    \"\"\"\n",
        "    Will return preprocess the current image for current index\n",
        "\n",
        "    @param colorcodec: the colorcodec used to transform the image\n",
        "\n",
        "    @return: the preprocessed image\n",
        "    \"\"\"\n",
        "    return preprocess_image(Image.open(self.__samples[self.__i]).convert(colorcodec), resize_im=True)\n",
        "\n",
        "  def get_original_image(self, colorcodec: str = 'RGB') -> Image:\n",
        "    \"\"\"\n",
        "    Will return the original image for current index\n",
        "\n",
        "    @param colorcodec: the colorcodec used to transform the image\n",
        "\n",
        "    @return: the original image\n",
        "    \"\"\"\n",
        "    return Image.open(self.__samples[self.__i]).convert(colorcodec)\n",
        "\n",
        "  def get_file_name(self) -> str:\n",
        "    \"\"\"\n",
        "    Will return the filename for current index\n",
        "\n",
        "    @return: the filename (without file-extension)\n",
        "    \"\"\"\n",
        "    return self.__samples[self.__i].split('/')[-1].split('.')[0]\n",
        "\n",
        "  def get_sample(self) -> str:\n",
        "    \"\"\"\n",
        "    Will return the set sample for current index\n",
        "\n",
        "    @return: the sample \n",
        "    \"\"\"\n",
        "    return self.__samples[self.__i]\n",
        "\n",
        "  def get_targeted_class(self) -> int:\n",
        "    \"\"\"\n",
        "    Will return targeted class for current index\n",
        "\n",
        "    @return: the number of targeted class\n",
        "    \"\"\"\n",
        "    return self.__classes[self.__i]\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.__samples)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbC_y2h6pUL7"
      },
      "source": [
        "def default_image_samples() -> ImageSamples:\n",
        "  \"\"\"\n",
        "  Will return a 'default' ImageSamples-object\n",
        "\n",
        "  @return: a ImageSamples-object with some predefined values\n",
        "  \"\"\"\n",
        "  return ImageSamples(image_paths = [\n",
        "    '/content/pytorch-cnn-visualizations/input_images/snake.jpg',   \n",
        "    '/content/pytorch-cnn-visualizations/input_images/cat_dog.png', \n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visj8EjXTi3V"
      },
      "source": [
        "# XAI-Functionality\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOh_mtJhfk3"
      },
      "source": [
        "## *GradientCam*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKApcJxrTjLr"
      },
      "source": [
        "class GradientCam:\n",
        "  \n",
        "  def __init__(self, gradient_cam_export_path: str = 'grad_cam', cam_heatmap_file_desc: str = '_cam_heatmap', cam_on_image_heatmap_file_desc: str = '_cam_on_image', cam_grayscale_file_desc: str = '_cam_grayscale', save_file_type: str = '.png'):\n",
        "    self.grad_cam = None\n",
        "    self.cam = None\n",
        "    self.gradient_cam_export_path = gradient_cam_export_path\n",
        "    self.cam_heatmap_file_desc = cam_heatmap_file_desc\n",
        "    self.cam_on_image_heatmap_file_desc = cam_on_image_heatmap_file_desc\n",
        "    self.cam_grayscale_file_desc = cam_grayscale_file_desc\n",
        "    if not save_file_type[0] == '.':\n",
        "      self.save_file_type = '.' + save_file_type\n",
        "    else:\n",
        "      self.save_file_type = save_file_type\n",
        "  \n",
        "  def run(self, model_wrapper, sample: ImageSamples, target_layer):\n",
        "    #print(f'Calculating GradientCam for Image \\'{sample.get_file_name()}\\' ...')\n",
        "    self.grad_cam = GradCam(model_wrapper.model, target_layer)\n",
        "    self.cam = self.grad_cam.generate_cam(sample.get_preprocessed_image(), sample.get_targeted_class())\n",
        "\n",
        "  def __generate_export_dir_path(self, model_export_path) -> str:\n",
        "    export_dir = model_export_path\n",
        "    if not export_dir[-1] == '/':\n",
        "      export_dir += '/'\n",
        "    if self.gradient_cam_export_path[0] == '/':\n",
        "      self.gradient_cam_export_path = self.gradient_cam_export_path[1:]\n",
        "    export_dir += self.gradient_cam_export_path\n",
        "    return export_dir\n",
        "\n",
        "  def save_class_activation_images(self, model_wrapper, sample: ImageSamples, file_start: str = '', colormap_name: str = 'hsv'):\n",
        "    # Generate export path\n",
        "    export_dir = self.__generate_export_dir_path(model_wrapper.model_export_path)\n",
        "\n",
        "    # Create export-directory\n",
        "    if not os.path.exists(export_dir):\n",
        "        os.makedirs(export_dir)\n",
        "\n",
        "    # Grayscale activation map\n",
        "    heatmap, heatmap_on_image = apply_colormap_on_image(samples.get_original_image(), self.cam, colormap_name)\n",
        "\n",
        "    # Save images\n",
        "    file_name = samples.get_file_name()    \n",
        "    save_image(heatmap, os.path.join(export_dir, file_start + file_name + self.cam_heatmap_file_desc + self.save_file_type))\n",
        "    save_image(heatmap_on_image, os.path.join(export_dir, file_start + file_name + self.cam_on_image_heatmap_file_desc + self.save_file_type))\n",
        "    save_image(self.cam, os.path.join(export_dir, file_start + file_name + self.cam_grayscale_file_desc + self.save_file_type))\n",
        "    #print(f'Saved GradientCam Image \\'{file_start+file_name}_*\\' to \\'{export_dir}\\' ...')\n",
        "\n",
        "  def show_class_activation_images(self, model_wrapper, sample: ImageSamples, images_per_row: int = 3, figsize: (int, int) = (200, 200)):\n",
        "    # Generate export path\n",
        "    export_dir = self.__generate_export_dir_path(model_wrapper.model_export_path)\n",
        "    file_names = []\n",
        "    samples.reset_index()\n",
        "    while samples.next():\n",
        "      file_names.append(samples.get_file_name())\n",
        "  \n",
        "    image_paths = []\n",
        "    for file_name in file_names:\n",
        "      paths = glob(f'{export_dir}/*{file_name}*{self.save_file_type}')\n",
        "      paths.sort()\n",
        "      image_paths.append(paths)\n",
        "    \n",
        "    def __translate_generated_file_name_to_subtitle(path: str) -> str:\n",
        "      if self.cam_heatmap_file_desc in path:\n",
        "        return 'CAM (Heatmap)'\n",
        "      elif self.cam_on_image_heatmap_file_desc in path:\n",
        "        return 'CAM (Heatmap) on Image'\n",
        "      elif self.cam_grayscale_file_desc in path:\n",
        "        return 'CAM (Grayscale)'\n",
        "      else:\n",
        "        return ''\n",
        "\n",
        "    for i, paths in enumerate(image_paths):\n",
        "      plot_images(paths, images_per_row, f'Image: {file_names[i]}', figsize, __translate_generated_file_name_to_subtitle)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO1TG_y0SVYp"
      },
      "source": [
        "# Neuronal-Networks\n",
        "---\n",
        "\n",
        "Here we declare our Neuralnetwork-Wrappers, which is mainly responsible to give access to specified model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoBQEJfASmMW"
      },
      "source": [
        "## *VGG-19*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqciakGBSgK-"
      },
      "source": [
        "class Wrapper_VGG19:\n",
        "\n",
        "  def __init__(self, pretrained: bool = True, model_export_path: str = '/content/results/vgg_19'):\n",
        "    self.pretrained = pretrained\n",
        "    self.model_export_path = model_export_path\n",
        "    self.model = None\n",
        "  \n",
        "  def build(self, pretrained: bool = True):\n",
        "    \"\"\"\n",
        "    Will\n",
        "\n",
        "    \"\"\"\n",
        "    self.model = models.vgg19(pretrained=pretrained)\n",
        "    return self\n",
        "  \n",
        "  def summary(self):\n",
        "    print(f'\\n{self.model}')\n",
        "\n",
        "  def get_targeted_layers(self) -> [int]:\n",
        "    return [\n",
        "      0,2,5,7,10,12,14,16,19,21,23,25,28,30,32,34\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLjbyor3bGdC"
      },
      "source": [
        "# GradientCam\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CrXt4ibbFbd"
      },
      "source": [
        "To view the result's of the Gradient am, we start with initializing the Samples-Objekt and the GradientCam-Objekt:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATTEg4ptbFsm"
      },
      "source": [
        "samples = default_image_samples()\n",
        "gradcam = GradientCam()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVUuLY9IhImm"
      },
      "source": [
        "## *VGG-19*\n",
        "\n",
        "Next up we will initialize the neural Networks and run the GradientCam with them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrBxS5kijIC6"
      },
      "source": [
        "vgg19 = Wrapper_VGG19(pretrained=True).build()\n",
        "vgg19.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlSpg1gwqxUZ"
      },
      "source": [
        "# show displaybar\n",
        "display_progress_bar(0, len(vgg19.get_targeted_layers()) * len(samples))\n",
        "\n",
        "for targeted_layer in vgg19.get_targeted_layers():\n",
        "  # reset samples\n",
        "  samples.reset_index()\n",
        "  # loop all samples:\n",
        "  while samples.next():\n",
        "    # calculate\n",
        "    gradcam.run(vgg19, samples, targeted_layer)\n",
        "    gradcam.save_class_activation_images(vgg19, samples, file_start=f'{targeted_layer:02d}_', colormap_name='hsv')\n",
        "    # update progress\n",
        "    update_progress_bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6gHQQ6UNLva"
      },
      "source": [
        "gradcam.show_class_activation_images(vgg19, samples, figsize=(20, 100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}